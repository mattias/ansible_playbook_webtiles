---
webserver: apache
protocol: http://
subdomain: crawl
domain: crawl-webtiles.com
admin_email: webmaster@crawl-webtiles.com
letsencrypt_email: "{{ admin_email }}"
chroot_dir: /home/crawl/DGL/
crawl_dev_dir: /home/crawl-dev/
ssh_username: terminal
crawl_users:
  - name: crawl
    groups: root,www-data
    uid: 1045
  - name: crawl-dev
    groups: root,www-data
    uid: 1046
system_users:
  - name: www-data
    groups: crawl,crawl-dev
  - name: root
    groups: crawl,crawl-dev
mounts:
  - proc
  - dev/pts

apache_remove_default_vhost: false
apache_listen_port_ssl: 8081
apache_vhosts:
  - servername: "www.{{ domain }}"
    extra_parameters: |
      Redirect / {{ protocol }}{{ subdomain }}.{{ domain }}:8080

  # - servername: "{{ domain }}"
  #   serveralias: "{{ subdomain }}.{{ domain }} www.{{ domain }}"
  #   documentroot: "/var/www/crawl"
  #   extra_parameters: |
  #     ServerAdmin {{ admin_email }}
  #
  #     SSLEngine on
  #
  #     SSLCertificateFile	/var/www/crawl_ssl/.crt
  #     SSLCertificateKeyFile /var/www/crawl_ssl/server.key
  #     SSLCertificateChainFile /var/www/crawl_ssl/.ca-bundle
  #
  #     <FilesMatch "\.(cgi|shtml|phtml|php)$">
  #     		SSLOptions +StdEnvVars
  #     </FilesMatch>
  #     <Directory /usr/lib/cgi-bin>
  #     		SSLOptions +StdEnvVars
  #     </Directory>
  #
  #     BrowserMatch "MSIE [2-6]" \
  #     		nokeepalive ssl-unclean-shutdown \
  #     		downgrade-1.0 force-response-1.0
  #     # MSIE 7 and newer should be able to use keepalive
  #     BrowserMatch "MSIE [17-9]" ssl-unclean-shutdown

  - servername: "{{ subdomain }}.{{ domain }}"
    documentroot: "/var/www/crawl"
    extra_parameters: |
      RewriteEngine on

      ScriptAlias /cgi-bin/ /usr/lib/cgi-bin/
      <Directory "/usr/lib/cgi-bin">
          AllowOverride None
          Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch
          Order allow,deny
          Allow from all
      </Directory>
      # Make an alias /saves/ that passes HTTP authentication information and
      # the save file name to auth-save-downloader.
      RewriteCond %{HTTP:Authorization} ^(.+)
      RewriteRule ^/saves/(.*)$ /cgi-bin/auth-save-downloader.pl?file=$1 [PT,E=HTTP_AUTHORIZATION:%1]
      RewriteRule ^/saves/(.*)$ /cgi-bin/auth-save-downloader.pl?file=$1 [PT]

      # Make an alias /rebuild/ that passes HTTP authentication information to
      # the rebuild trigger.
      RewriteCond %{HTTP:Authorization} ^(.+)
      RewriteRule ^/rebuild(/(.*))?$ /cgi-bin/trigger-rebuild.pl?v=$2 [PT,E=HTTP_AUTHORIZATION:%1]
      RewriteRule ^/rebuild(/(.*))?$ /cgi-bin/trigger-rebuild.pl?v=$2 [PT]

      RewriteCond %{REQUEST_URI} ^/ttyrec/([^/]*)/(.*\.ttyrec)
      RewriteCond /var/www/%{REQUEST_FILENAME} !-f
      RewriteRule ^/ttyrec/([^/]*)/(.*\.ttyrec)$ /ttyrec/$1/$2.bz2
      RewriteRule ^/crawl - [L]
      RewriteRule ^/crawl/morgue - [L]
      RewriteRule ^/crawl/rcfiles - [L]
      RewriteRule ^/crawl/ttyrec - [L]
      RewriteRule ^/crawl/meta - [L]

      # Turn off compression for /rebuild so we can see compile messages in real time.
      SetEnvIfNoCase Request_URI ^/rebuild(/.*)?$ no-gzip dont-vary
      RewriteRule ^/(.*) {{ protocol }}{{ subdomain }}.{{ domain }}:8080/$1

region: Sweden
server_admin: Mattias

# dgamelaunch.conf variables
max_users: "64000"
server_id: "CCW - Dungeon Crawl Stone Soup - {{ subdomain }}.{{ domain }}"
server_name: "ccw"
versions:
  - "0.18"
experimentals:
  - "combo_god"
port: "8080"
ssl: False

# letsencrypt TODO
letsencrypt_defaults:
  dir: store/letsencrypt-test
  email: 'webmaster@{{ domain }}'
  host: "{{ domain }}"
  webroot: /var/www/crawl_ssl
  min_days: 7
  domains_key_size: 4096
  user_key_size: 4096
  staging: yes
letsencrypt_certificates:
  - domains:
      - name: "{{ domain }}"
        cn: yes
      - "{{ subdomain }}.{{ domain }}"
